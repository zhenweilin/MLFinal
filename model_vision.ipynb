{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('tc': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a69dc6475e010b638fc9e3120b8052e1658281da94903e1c368775d94b70048c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "modelName: MobileNetV1\n"
     ]
    }
   ],
   "source": [
    "model_path = './checkpoints/SGD_l1_mobilenetv1_chestX_10_edi_2.3_theta_10_lam_4.0e-04.pt'\n",
    "checkpoint = torch.load(model_path,map_location='cpu')\n",
    "model = selectModel('mobilenetv1')\n",
    "model.load_state_dict = checkpoint['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchvision.models import AlexNet\n",
    "    from torch.autograd import Variable\n",
    "    import torch\n",
    "\n",
    "    # net = AlexNet()\n",
    "    x = Variable(torch.randn((32,1,960,960)))#out_channel, input channel, image_size length*height\n",
    "    y = model(x)\n",
    "    g = make_dot(y)\n",
    "    g.view()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 32, 28, 28]             288\n       BatchNorm2d-2           [-1, 32, 28, 28]              64\n            Conv2d-3           [-1, 32, 28, 28]             288\n       BatchNorm2d-4           [-1, 32, 28, 28]              64\n            Conv2d-5           [-1, 64, 28, 28]           2,048\n       BatchNorm2d-6           [-1, 64, 28, 28]             128\n             Block-7           [-1, 64, 28, 28]               0\n            Conv2d-8           [-1, 64, 14, 14]             576\n       BatchNorm2d-9           [-1, 64, 14, 14]             128\n           Conv2d-10          [-1, 128, 14, 14]           8,192\n      BatchNorm2d-11          [-1, 128, 14, 14]             256\n            Block-12          [-1, 128, 14, 14]               0\n           Conv2d-13          [-1, 128, 14, 14]           1,152\n      BatchNorm2d-14          [-1, 128, 14, 14]             256\n           Conv2d-15          [-1, 128, 14, 14]          16,384\n      BatchNorm2d-16          [-1, 128, 14, 14]             256\n            Block-17          [-1, 128, 14, 14]               0\n           Conv2d-18            [-1, 128, 7, 7]           1,152\n      BatchNorm2d-19            [-1, 128, 7, 7]             256\n           Conv2d-20            [-1, 256, 7, 7]          32,768\n      BatchNorm2d-21            [-1, 256, 7, 7]             512\n            Block-22            [-1, 256, 7, 7]               0\n           Conv2d-23            [-1, 256, 7, 7]           2,304\n      BatchNorm2d-24            [-1, 256, 7, 7]             512\n           Conv2d-25            [-1, 256, 7, 7]          65,536\n      BatchNorm2d-26            [-1, 256, 7, 7]             512\n            Block-27            [-1, 256, 7, 7]               0\n           Conv2d-28            [-1, 256, 4, 4]           2,304\n      BatchNorm2d-29            [-1, 256, 4, 4]             512\n           Conv2d-30            [-1, 512, 4, 4]         131,072\n      BatchNorm2d-31            [-1, 512, 4, 4]           1,024\n            Block-32            [-1, 512, 4, 4]               0\n           Conv2d-33            [-1, 512, 4, 4]           4,608\n      BatchNorm2d-34            [-1, 512, 4, 4]           1,024\n           Conv2d-35            [-1, 512, 4, 4]         262,144\n      BatchNorm2d-36            [-1, 512, 4, 4]           1,024\n            Block-37            [-1, 512, 4, 4]               0\n           Conv2d-38            [-1, 512, 4, 4]           4,608\n      BatchNorm2d-39            [-1, 512, 4, 4]           1,024\n           Conv2d-40            [-1, 512, 4, 4]         262,144\n      BatchNorm2d-41            [-1, 512, 4, 4]           1,024\n            Block-42            [-1, 512, 4, 4]               0\n           Conv2d-43            [-1, 512, 4, 4]           4,608\n      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n           Conv2d-45            [-1, 512, 4, 4]         262,144\n      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n            Block-47            [-1, 512, 4, 4]               0\n           Conv2d-48            [-1, 512, 4, 4]           4,608\n      BatchNorm2d-49            [-1, 512, 4, 4]           1,024\n           Conv2d-50            [-1, 512, 4, 4]         262,144\n      BatchNorm2d-51            [-1, 512, 4, 4]           1,024\n            Block-52            [-1, 512, 4, 4]               0\n           Conv2d-53            [-1, 512, 4, 4]           4,608\n      BatchNorm2d-54            [-1, 512, 4, 4]           1,024\n           Conv2d-55            [-1, 512, 4, 4]         262,144\n      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n            Block-57            [-1, 512, 4, 4]               0\n           Conv2d-58            [-1, 512, 2, 2]           4,608\n      BatchNorm2d-59            [-1, 512, 2, 2]           1,024\n           Conv2d-60           [-1, 1024, 2, 2]         524,288\n      BatchNorm2d-61           [-1, 1024, 2, 2]           2,048\n            Block-62           [-1, 1024, 2, 2]               0\n           Conv2d-63           [-1, 1024, 2, 2]           9,216\n      BatchNorm2d-64           [-1, 1024, 2, 2]           2,048\n           Conv2d-65           [-1, 1024, 2, 2]       1,048,576\n      BatchNorm2d-66           [-1, 1024, 2, 2]           2,048\n            Block-67           [-1, 1024, 2, 2]               0\n           Linear-68                    [-1, 2]           2,050\n================================================================\nTotal params: 3,208,450\nTrainable params: 3,208,450\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 3.52\nForward/backward pass size (MB): 6.59\nParams size (MB): 12.24\nEstimated Total Size (MB): 22.35\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary          #使用 pip install torchsummary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "a = summary(model, input_size=(1, 192*5, 192*5)) # image size 1 channel,192*5 * 192*5"
   ]
  }
 ]
}