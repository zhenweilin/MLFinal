{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from run import selectModel\n",
    "from torchvision.models import AlexNet\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "modelName: MobileNetV1\n"
     ]
    }
   ],
   "source": [
    "model_path = './checkpoints/SGD_l1_mobilenetv1_chestX_10_edi_2.0_theta_10_lam_1.0e-04.pt'\n",
    "checkpoint = torch.load(model_path,map_location='cpu')\n",
    "model = selectModel('mobilenetv1')\n",
    "model.load_state_dict = checkpoint['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchvision.models import AlexNet\n",
    "    from torch.autograd import Variable\n",
    "    import torch\n",
    "\n",
    "    # net = AlexNet()\n",
    "    x = Variable(torch.randn((32,1,960,960)))#out_channel, input channel, image_size length*height\n",
    "    y = model(x)\n",
    "    g = make_dot(y)\n",
    "    g.view()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 32, 48, 48]             288\n       BatchNorm2d-2           [-1, 32, 48, 48]              64\n            Conv2d-3           [-1, 32, 48, 48]             288\n       BatchNorm2d-4           [-1, 32, 48, 48]              64\n            Conv2d-5           [-1, 64, 48, 48]           2,048\n       BatchNorm2d-6           [-1, 64, 48, 48]             128\n             Block-7           [-1, 64, 48, 48]               0\n            Conv2d-8           [-1, 64, 24, 24]             576\n       BatchNorm2d-9           [-1, 64, 24, 24]             128\n           Conv2d-10          [-1, 128, 24, 24]           8,192\n      BatchNorm2d-11          [-1, 128, 24, 24]             256\n            Block-12          [-1, 128, 24, 24]               0\n           Conv2d-13          [-1, 128, 24, 24]           1,152\n      BatchNorm2d-14          [-1, 128, 24, 24]             256\n           Conv2d-15          [-1, 128, 24, 24]          16,384\n      BatchNorm2d-16          [-1, 128, 24, 24]             256\n            Block-17          [-1, 128, 24, 24]               0\n           Conv2d-18          [-1, 128, 12, 12]           1,152\n      BatchNorm2d-19          [-1, 128, 12, 12]             256\n           Conv2d-20          [-1, 256, 12, 12]          32,768\n      BatchNorm2d-21          [-1, 256, 12, 12]             512\n            Block-22          [-1, 256, 12, 12]               0\n           Conv2d-23          [-1, 256, 12, 12]           2,304\n      BatchNorm2d-24          [-1, 256, 12, 12]             512\n           Conv2d-25          [-1, 256, 12, 12]          65,536\n      BatchNorm2d-26          [-1, 256, 12, 12]             512\n            Block-27          [-1, 256, 12, 12]               0\n           Conv2d-28            [-1, 256, 6, 6]           2,304\n      BatchNorm2d-29            [-1, 256, 6, 6]             512\n           Conv2d-30            [-1, 512, 6, 6]         131,072\n      BatchNorm2d-31            [-1, 512, 6, 6]           1,024\n            Block-32            [-1, 512, 6, 6]               0\n           Conv2d-33            [-1, 512, 6, 6]           4,608\n      BatchNorm2d-34            [-1, 512, 6, 6]           1,024\n           Conv2d-35            [-1, 512, 6, 6]         262,144\n      BatchNorm2d-36            [-1, 512, 6, 6]           1,024\n            Block-37            [-1, 512, 6, 6]               0\n           Conv2d-38            [-1, 512, 6, 6]           4,608\n      BatchNorm2d-39            [-1, 512, 6, 6]           1,024\n           Conv2d-40            [-1, 512, 6, 6]         262,144\n      BatchNorm2d-41            [-1, 512, 6, 6]           1,024\n            Block-42            [-1, 512, 6, 6]               0\n           Conv2d-43            [-1, 512, 6, 6]           4,608\n      BatchNorm2d-44            [-1, 512, 6, 6]           1,024\n           Conv2d-45            [-1, 512, 6, 6]         262,144\n      BatchNorm2d-46            [-1, 512, 6, 6]           1,024\n            Block-47            [-1, 512, 6, 6]               0\n           Conv2d-48            [-1, 512, 6, 6]           4,608\n      BatchNorm2d-49            [-1, 512, 6, 6]           1,024\n           Conv2d-50            [-1, 512, 6, 6]         262,144\n      BatchNorm2d-51            [-1, 512, 6, 6]           1,024\n            Block-52            [-1, 512, 6, 6]               0\n           Conv2d-53            [-1, 512, 6, 6]           4,608\n      BatchNorm2d-54            [-1, 512, 6, 6]           1,024\n           Conv2d-55            [-1, 512, 6, 6]         262,144\n      BatchNorm2d-56            [-1, 512, 6, 6]           1,024\n            Block-57            [-1, 512, 6, 6]               0\n           Conv2d-58            [-1, 512, 3, 3]           4,608\n      BatchNorm2d-59            [-1, 512, 3, 3]           1,024\n           Conv2d-60           [-1, 1024, 3, 3]         524,288\n      BatchNorm2d-61           [-1, 1024, 3, 3]           2,048\n            Block-62           [-1, 1024, 3, 3]               0\n           Conv2d-63           [-1, 1024, 3, 3]           9,216\n      BatchNorm2d-64           [-1, 1024, 3, 3]           2,048\n           Conv2d-65           [-1, 1024, 3, 3]       1,048,576\n      BatchNorm2d-66           [-1, 1024, 3, 3]           2,048\n            Block-67           [-1, 1024, 3, 3]               0\n           Linear-68                    [-1, 3]           3,075\n================================================================\nTotal params: 3,209,475\nTrainable params: 3,209,475\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 3.52\nForward/backward pass size (MB): 17.93\nParams size (MB): 12.24\nEstimated Total Size (MB): 33.69\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "       #使用 pip install torchsummary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "a = summary(model, input_size=(1, 192*5, 192*5)) # image size 1 channel,192*5 * 192*5"
   ]
  }
 ]
}